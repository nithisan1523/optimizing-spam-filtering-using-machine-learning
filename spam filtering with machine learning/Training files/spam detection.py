# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TH0xKUFTdVl9FU6GP8IRzFRubhnwpC7G
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import re
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from nltk.corpus import wordnet
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')

import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("spam_ham_dataset.csv")
df.head()

df = df.drop(['Unnamed: 0'], axis=1)
df.head()

"""Exploratory Data Analysis"""

print('Count %s data email'% len(df))

df['label'].value_counts()

df['label'] = df['label'].replace(['ham'],'non-spam')

df['label'].value_counts().plot(kind="bar",figsize=(12,6))
plt.xticks(np.arange(2),('non-spam','spam'))

print(df['text'][0])

"""Preprocessing"""

df = df.groupby('label').head(1000)

df['label'].value_counts()

"""Text Cleaning"""

import string

punct = []
for char in string.punctuation:
    punct.append(char)

def cleaning(txt):
    # case folding
    text = txt.lower()
    
    # remove multiple space, tabs, dan newlines
    text = re.sub('\s+',' ',text)
    
    # remove links
    text = text.replace("http://", " ").replace("https://", " ")
    
    # remove special characters
    text = text.encode('ascii', 'replace').decode('ascii')
    text = ' '.join(re.sub("([@#][A-Za-z0-9]+)|(\w+:\/\/\S+)"," ", text).split())
    
    # remove punctuation
    text = ''.join([word for word in text if word not in punct])
    
    #remove single character
    text = re.sub(r"\b[a-zA-Z]\b", "", text)
    
    #remove numbers
    text = re.sub(r"\d+", "", text)
    
    #remove multiple spaces (again)
    text = re.sub('\s+',' ',text)
    
    return text

df['text_cleaned'] = df['text'].apply(lambda x: cleaning(x))
df = df[['text', 'text_cleaned', 'label']]
df.head()

"""Stopword Removal"""

stop = stopwords.words('english')
df['text_cleaned'] = df['text_cleaned'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))

"""Lemmatization"""

lemmatizer = WordNetLemmatizer()

# mapping the POS tags
def get_wordnet_pos(word):
    """Map POS tag to first character lemmatize() accepts"""
    tag = nltk.pos_tag([word])[0][1][0].upper()
    tag_dict = {"J": wordnet.ADJ,
                "N": wordnet.NOUN,
                "V": wordnet.VERB,
                "R": wordnet.ADV}

    return tag_dict.get(tag, wordnet.NOUN)   

def do_lemma(string):
    lemmatized = ' '.join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in nltk.word_tokenize(string)])
    return lemmatized

sentence = "The striped bats are hanging on their feet for best"
lemmatized = ' '.join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in nltk.word_tokenize(sentence)])
print(do_lemma(sentence))

df['text_cleaned'] = df['text_cleaned'].apply(lambda x: do_lemma(x))

df.head()

"""Data Preparation"""

df = df.drop(['text'], axis=1)
df = df.rename(columns = {'text_cleaned' : 'text'})
df.columns

"""Feature Extraction using TF-IDF"""

tfidf = TfidfVectorizer()
X = tfidf.fit_transform(df['text'])
y = df['label']

"""train test split"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Build Model

1.Naive Bayes
"""

clf_nb = MultinomialNB()
clf_nb.fit(X_train, y_train)

pred_nb = clf_nb.predict(X_test)

"""2.Logistic Regression"""

clf_lr=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')
clf_lr.fit(X_train, y_train)

pred_lr = clf_lr.predict(X_test)

"""3.Random Forest"""

clf_rf = RandomForestClassifier(n_estimators=100, criterion="gini")
clf_rf.fit(X_train, y_train)

pred_rf = clf_rf.predict(X_test)

"""Evaluation"""

print(classification_report(y_test,pred_nb))

print('Accuracy model Naive Bayes: %0.2f' % (accuracy_score(y_test, pred_nb)*100), '%')

print(classification_report(y_test,pred_lr))

print('Accuracy model Logistic Regression: %0.2f' % (accuracy_score(y_test, pred_lr)*100), '%')

print(classification_report(y_test,pred_rf))

print('Accuracy model Random Forest: %0.2f' % (accuracy_score(y_test, pred_rf)*100), '%')

pip install flask

from flask import flask,render_template,request
import pickle
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import porterstemmer
from tensorflow.keras.models import load_model